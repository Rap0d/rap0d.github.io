---
layout: post
title: 52. Naive Bayes
subtitle: Naive Bayes
categories: study
tags: rprogramming
---

![r](/assets/img/logo/r-logo.png)

# Overview

Naive Bayes 알고리즘은 속성을 사용하여 분류를 하고자 할때, 확률의 원리를 활용하는 알고리즘이다.

미래 사건 확률을 추정하기 위해 과거의 데이터를 활용한다.

조건부 확률이라는 개념과 베이즈 정리를 이용하여 만든 알고리즘이다.

> 사용처  
> 스팸 메일 분류  
> 저자 식별과 문서 분류  
> 질병에 대한 진찰

***

# 기본 개념

베이즈 확률 이론은 유사한 증거를 기반으로 한 사건의 유사성을 추정하는 개념에 근거를 두고 있다. 

사건(event)이란 확률을 계산하기 위한 결과의 집합을 의미한다.

예를 들어, 화창하거나 비가 올 날씨, 동전의 앞면과 뒷면 등이다.

***

# 확률(Probability)

사건의 확률은 사건이 일어난 시도의 숫자를 총 사건의 수로 나눈 수를 의미한다.

모든 확률의 총 합은 1이다.

## 베이즈 확률 이론

유사한 증거를 기반으로 한 사건의 유사성을 추정한다.

## 독립 사건

두 개의 사건이 전혀 연관성이 없는 사건을 말한다.

$$P(A\cap B)=P(A)\times P(B)$$

## 종속 사건

두 개의 사건이 서로 연관성이 있는 사건

***

# 확률의 표기법

다음과 같은 도서 대출 현황표가 있다고 가정한다.

> 전체 고객 수 : 100  
> Tensorflow 책을 구매한 고객 수 : 50  
> Database 책을 구매한 고객 수 : 20  
> 두 권 모두를 구매한 고객 수 : 10

이에 대한 확률 표기법은 다음과 같은 항목들이 있다.

| 확률 표현 | 수식 표현 | 설명 |
|:----:|:----:|:----|
| $$P(A)$$ | 50/100 | Tensorflow 책을 구매한 확률 |
| $$P(B)$$ | 20/100 | Database 책을 구매한 확률 |
| $$P(B\mid A)$$ | 10/50 | Tensorflow 책을 구매자 중에서<br>Database 책도 같이 구매한 확률 |
| $$P(A\mid B)$$ | 10/20 | Database 책을 구매자 중에서<br>Tensorflow 책도 같이 구매한 확률 |
| $$P(\sim B)$$ | (100-20)/100 | Database 책을 구매하지 않을 확률 |

***

# 스팸 필터

다음과 같이 전체 메일 중에서 스팸 메일을 걸러 주는 Spam-Filter 기가 있고, 전체 메일에서 스팸 메일은 30%라고 가정하자.

사건 A를 스팸 메일이라고 한다면 표기법은 다음과 같다.

> $$P(A)$$ = 0.3 : 스팸 메일의 확률은 30%이다.  
> $$P(\sim A)$$ = 0.7 : 스팸 메일이 아닐 확률은 80%이다.

이메일에 '할인'이라는 단어가 들어있을 수 있다.

전체에서 스팸 메일은 30% 차지하고, '할인'이라는 단어가 들어 있는 메일은 20%이다.

스팸 메일이면서, '할인'이라는 단어가 들어 있는 메일은 전체의 10%이다.

> 전체 메일 수 : 100  
> 스팸 메일 수 : 30  
> '할인'이라는 단어가 들어있는 메일 수 : 20  
> 스팸 메일 중에서 '할인'이라는 단어가 들어있는 메일 수 : 10

## 확률 표기

모든 사건들에 대한 확률은 다음과 같다.

| 확률 표현 | 수식 표현 | 설명 |
|:----:|:----:|:----|
| $$P(S)$$ | 30/100 | 스팸 메일의 확률 |
| $$P(B)$$ | 20/100 | '할인'이라는 단어가 들어 있는 메일의 확률 |
| $$P(B\mid S)$$ | 10/30 | 스팸 메일에서 '할인'이라는 단어가 들어 있는 메일의 확률 |
| $$P(S\mid B)$$ | 10/20 | '할인'이라는 단어가 들어 있는 메일중에서 스팸 메일의 확률 |

***

# 조건부 확률

조건부 확률이란 어떠한 사건 A가 일어났다는 전제하에서 다른 사건 B가 발생할 확률을 의미한다. 

수식으로는 $$P(A\mid B)$$라고 표현한다.

확률의 기본 정리인 곱셈 정리를 응용한 것이다.

$$P(A\mid B)={P(B\mid A)\times P(A)\over P(B)}={P(A\cap B)\over P(B)}$$

## 예시

주사위를 두 번 던져서 "첫번째가 3", "두번째가 짝수"가 될 확률은 다음과 같다.

3은 확률이 1/6이고, 짝수는 3/6=1/2이므로, 곱셈 법칙에 의하여 1/6*1/2 = 1/12이다.

만약 두 사건이 독립 사건이라면 다음과 같은 공식이 성립한다.

$$P(A\cap B)=P(A)\times P(B)$$

***

# 스팸 메일 분류기 베이즈 이론

베이즈 이론이 어떻게 동작하는지 이해하기 위하여 수신 받은 이메일이 스팸일 확률을 구한다고 가정하자. 

- 사전(Prior) 확률
  - 이미 알고 있는 이전 사건들에 대한 확률
  - 이전 메일이 Spam 메일인 확률
- 우도(Likelihood)
  - 이미 알고 있는 사건들이 발생했다는 전제에<br>다른 사건이 발생할 확률
- 주변(Marginal) 우도
  - 모든 메일에 '할인'이 나타난 확률
- 사후(Posterior) 확률
  - 사전 확률과 우도 확률을 통해서 알게 되는 조건부 확률
  - 베이즈 이론을 적용하여 이 메일이 Spam 메일일 확률
  
다음 공식은 스팸 메일 분류기에 대한 그림이다.

![fig02](/assets/img/study/r/191125_fig_02.png)

위 공식에서 Posterior 확률이 50%보다 크거나 같으면, 이 메일은 Spam 메일로 본다.

***

# Frequency Table and Likelihood Table

베이즈 이론의 요소를 계산하기 위해 Spam과 일반 메일에서 '할인'이 나타내는 횟수를 Frequency Table로 작성할 수 있다.

이원 교차표 형식으로 작성하며, 행에는 범주, 열에는 속성을 표시한다.

| Frequency | 할인 O | 할인 X | total |
|:----:|:----:|:----:|:----:|
| Spam | 10 | 20 | 30 |
| Pass | 10 | 60 | 70 |
| total | 20 | 80 | 100 |

Frequency Table은 다음과 같이 Likelihood Table을 구성하는데 사용한다.

| Likelihood | 할인 O | 할인 X | total |
|:----:|:----:|:----:|:----:|
| Spam | 10/30 | 20/30 | 30 |
| Pass | 10/70 | 60/70 | 70 |
| total | 20/100 | 80/100 | 100 |

Likelihood Table을 살펴보면 P(할인/스팸) = 10/30이며, 할인이 포함되어 있는 스팸 메일이 1/3임을 나타내고 있다.

P(스팸/할인) 사후 확률을 계산해보면, P(할인/스팸) * P(스팸) / P(할인) = (10/30) * (30/100) / (20/100) = 1/2 = 0.5이다.

그러므로, 메일에 할인이라는 단어가 포함이 되었을 경우 스팸 메일일 확률이 50%라는 것을 알 수 있다.

데이터의 개수가 많아지면, 이 메일이 스팸일 확률은 높아질 것이다.

***

# Naive Bayes 함수

나이브 베이즈와 관련된 패키지는 'e1071'이다. 

참고로 klaR 패키지의 `NaiveBayes()`도 존재한다.

```R
install.packages('e1071')
library(e1071) # 나이브 베이즈 구현 패키지
```

## naiveBayes() 함수

나이브 베이즈 분류기를 만들어 준다.

- 사용 형식
  -  `someObj <- naiveBayes(training, class, laplace=0)`
  -  반환되는 객체(someObj)는 "naiveBayes" 타입
- training
  - 훈련 데이터(training)가 포함되어 있는 dataframe 또는 matrix
- class
  -  훈련 데이터의 각 행에 대한 범주 정보를 담고 있는 팩터 벡터
  -  정답을 가지고 있는 label 
- laplace
  - 라플라스 추정기를 제어하는 숫자
  - 일반적으로 적어도 1번 정도는 각 범주에 속한 것처럼 값을 1로 설정

> ### 라플라스 추정기  
> 프랑스 수학자 피에르 시몬 라플라스가 제안한 개념이다.  
> 발생할 확률 값이 0이 되지 않도록 각 빈도의 값에 적은 수를 추가하는 개념이다.  
> 일반적으로 적어도 한 번 각 범주에 속한 것처럼 라플라스 추정기는 1로 설정한다.

## predict() 함수

나이브 베이즈 분류기에 대한 예측을 수행해주는 함수이다.

- 사용 형식
  - `pred <- predict(navObj, testing[, type])`
- navObj
  - naiveBayes 함수를 이용하여 구한 "naiveBayes" 타입의 객체를 의미
- testing
  - 검정용 데이터(testing)가 포함되어 있는 dataframe 또는 matrix
- type
  - 예측이 범주 값(class)이든지 원시 예측 확률(raw)인지 명시하는 옵션